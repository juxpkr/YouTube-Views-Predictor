import os
import sys
import requests
import pandas as pd
import psycopg2
from collections import Counter
from konlpy.tag import Okt
from datetime import datetime, timedelta
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from models import db, YouTubeTrending  # âœ… DB ì—°ë™ì„ ìœ„í•´ ê°€ì ¸ì˜´
from flask import Flask  # âœ… DB ì—°ë™ì„ ìœ„í•œ Flask ì•± ìƒì„±
from config import DB_CONFIG

# âœ… Flask ì•± ì„¤ì • (DB ì—°ê²°)
app = Flask(__name__)
app.config["SQLALCHEMY_DATABASE_URI"] = f"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}"
app.config["SQLALCHEMY_TRACK_MODIFICATIONS"] = False
db.init_app(app)

# âœ… PostgreSQL ì—°ê²° ì„¤ì •
def connect_db():
    return psycopg2.connect(**DB_CONFIG)

# âœ… ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
def load_stopwords():
    stopwords_path = os.path.join(os.path.dirname(__file__), "stopwords.txt")
    if os.path.exists(stopwords_path):
        with open(stopwords_path, "r", encoding="utf-8") as f:
            stopwords = [line.strip() for line in f.readlines()]
    else:
        stopwords = []
    return stopwords

stopwords = load_stopwords()
print(f"âœ… ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì™„ë£Œ! {len(stopwords)}ê°œ ë‹¨ì–´ í•„í„°ë§ ì˜ˆì •")

# âœ… í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
okt = Okt()

# âœ… íŠ¹ì • ë‚ ì§œì˜ ìœ íŠœë¸Œ ì œëª© ë¶ˆëŸ¬ì˜¤ê¸° (ì˜¤ëŠ˜, ì–´ì œ)
def fetch_titles_from_db(days_ago=0):
    conn = connect_db()
    cur = conn.cursor()

    query = """
    SELECT title FROM youtube_trending
    WHERE fetched_at::DATE = NOW()::DATE - INTERVAL '%s days';
    """
    cur.execute(query, (days_ago,))
    titles = [row[0] for row in cur.fetchall()]
    
    conn.close()
    return titles

# âœ… í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜
def extract_keywords(titles):
    keywords = []
    for title in titles:
        nouns = okt.nouns(title)  # ëª…ì‚¬ ì¶”ì¶œ
        keywords.extend([word for word in nouns if word not in stopwords and len(word) > 1])
    return Counter(keywords)

# âœ… ì˜¤ëŠ˜ê³¼ ì–´ì œ í‚¤ì›Œë“œ ì¶”ì¶œ
today_titles = fetch_titles_from_db(0)  # ì˜¤ëŠ˜ ë°ì´í„°
yesterday_titles = fetch_titles_from_db(1)  # ì–´ì œ ë°ì´í„°

today_keywords = extract_keywords(today_titles)
yesterday_keywords = extract_keywords(yesterday_titles)

# âœ… ë°ì´í„°í”„ë ˆìž„ ë³€í™˜
df_today = pd.DataFrame(today_keywords.items(), columns=["Keyword", "TodayCount"])
df_yesterday = pd.DataFrame(yesterday_keywords.items(), columns=["Keyword", "YesterdayCount"])

# âœ… í‚¤ì›Œë“œ ë³€í™” ë¶„ì„ (í•©ì§‘í•© í›„ ë¹„êµ)
df_merge = pd.merge(df_today, df_yesterday, on="Keyword", how="outer")

# âœ… fillna(0) í›„ ìžë™ ë‹¤ìš´ìºìŠ¤íŒ… ë°©ì§€
df_merge = df_merge.infer_objects(copy=False)

# âœ… ì•ˆì „í•˜ê²Œ ìˆ«ìžë¡œ ë³€í™˜
df_merge["TodayCount"] = pd.to_numeric(df_merge["TodayCount"].fillna(0))
df_merge["YesterdayCount"] = pd.to_numeric(df_merge["YesterdayCount"].fillna(0))
df_merge["Difference"] = df_merge["TodayCount"] - df_merge["YesterdayCount"]


# âœ… ë³€í™” ìœ í˜• ë¶„ë¥˜
def classify_change(row):
    if row["YesterdayCount"] == 0:
        return "NEW"
    elif row["TodayCount"] == 0:
        return "DISAPPEARED"
    elif row["Difference"] > 0:
        return "INCREASED"
    elif row["Difference"] < 0:
        return "DECREASED"
    else:
        return "NO_CHANGE"

df_merge["ChangeType"] = df_merge.apply(classify_change, axis=1)

# âœ… ê¸°ì¡´ í‚¤ì›Œë“œ ë°±ì—… (fetched_at ì¶”ê°€í•˜ì—¬ ìœ ì§€)
def backup_old_keywords():
    conn = connect_db()
    cur = conn.cursor()
    
    query = """
    INSERT INTO youtube_trending_keywords_old (Keyword, Count, fetched_at)
    SELECT Keyword, Count, NOW() FROM youtube_trending_keywords;
    """
    cur.execute(query)
    conn.commit()
    conn.close()
    print("âœ… ê¸°ì¡´ í‚¤ì›Œë“œ ë°ì´í„°ë¥¼ youtube_trending_keywords_old í…Œì´ë¸”ì— ë°±ì—… ì™„ë£Œ!")

# âœ… PostgreSQLì— ìƒˆë¡œìš´ í‚¤ì›Œë“œ ë°ì´í„° ì €ìž¥
def save_keywords_to_db():
    conn = connect_db()
    cur = conn.cursor()

    # âœ… ìƒˆë¡œìš´ í‚¤ì›Œë“œ ë°ì´í„° ì‚½ìž… (ì¤‘ë³µ ì €ìž¥ í—ˆìš©)
    for _, row in df_today.iterrows():
        query = """
        INSERT INTO youtube_trending_keywords (Keyword, Count, fetched_at) 
        VALUES (%s, %s, NOW());
        """
        cur.execute(query, (row["Keyword"], row["TodayCount"]))

    conn.commit()
    conn.close()
    print("âœ… ìƒˆë¡œìš´ í‚¤ì›Œë“œ ë°ì´í„°ë¥¼ PostgreSQLì— ì €ìž¥ ì™„ë£Œ!")

# âœ… í‚¤ì›Œë“œ ë³€í™” ë°ì´í„° ì €ìž¥ (fetched_at ì¶”ê°€)
def save_keyword_changes():
    conn = connect_db()
    cur = conn.cursor()

    for _, row in df_merge.iterrows():
        query = """
        INSERT INTO youtube_trending_keyword_changes (Keyword, OldCount, NewCount, Difference, ChangeType, fetched_at) 
        VALUES (%s, %s, %s, %s, %s, NOW());
        """
        cur.execute(query, (row["Keyword"], row["YesterdayCount"], row["TodayCount"], row["Difference"], row["ChangeType"]))

    conn.commit()
    conn.close()
    print("âœ… í‚¤ì›Œë“œ ë³€í™” ë°ì´í„°ë¥¼ PostgreSQLì— ì €ìž¥ ì™„ë£Œ!")

# âœ… ê¸°ì¡´ í‚¤ì›Œë“œ ë°ì´í„° ë°±ì—… & ìµœì‹  í‚¤ì›Œë“œ ì €ìž¥
backup_old_keywords()
save_keywords_to_db()
save_keyword_changes()

# âœ… CSV íŒŒì¼ ì €ìž¥ (í™•ì¸ìš©)
csv_path = os.path.join(os.path.dirname(__file__), "youtube_trending_keywords.csv")
df_merge.to_csv(csv_path, index=False, encoding="utf-8-sig")
print(f"âœ… CSV ì €ìž¥ ì™„ë£Œ (í™•ì¸ìš©): {csv_path}")

# âœ… ìƒìœ„ ë³€í™” í‚¤ì›Œë“œ ì¶œë ¥
top_keywords = df_merge.sort_values(by="Difference", ascending=False).head(20)

print("\nðŸ“Œ **ìœ íŠœë¸Œ íŠ¸ë Œë“œ í‚¤ì›Œë“œ TOP 20**")
for idx, row in top_keywords.iterrows():
    print(f"{row['Keyword']}: {row['Difference']}íšŒ ({row['ChangeType']})")

print("\nâœ… í‚¤ì›Œë“œ ë¶„ì„ ë° ì €ìž¥ ì™„ë£Œ!")

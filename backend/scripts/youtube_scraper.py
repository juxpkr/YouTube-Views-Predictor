import os
import sys
import requests
import pandas as pd
from datetime import datetime
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from models import db, YouTubeTrending  # âœ… DB ì—°ë™ì„ ìœ„í•´ ê°€ì ¸ì˜´
from flask import Flask  # âœ… DB ì—°ë™ì„ ìœ„í•œ Flask ì•± ìƒì„±
from config import DB_CONFIG

# ğŸ“Œ Flask ì•± ì„¤ì • (DB ì—°ê²°)
app = Flask(__name__)

# ğŸ“Œ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
app.config["SQLALCHEMY_DATABASE_URI"] = f"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}"
app.config["SQLALCHEMY_TRACK_MODIFICATIONS"] = False
db.init_app(app)

# ğŸ“Œ YouTube API ì„¤ì •
API_KEY = "AIzaSyD1nEO18khr0wunaEm0SogZnhU6ewNIpxE"
BASE_URL = "https://www.googleapis.com/youtube/v3/"

# ğŸ“Œ ì¹´í…Œê³ ë¦¬ ID â†’ ì´ë¦„ ë§¤í•‘
def get_category_mapping(region_code="KR"):
    url = f"{BASE_URL}videoCategories?part=snippet&regionCode={region_code}&key={API_KEY}"
    response = requests.get(url)

    if response.status_code != 200:
        print("âŒ Error fetching categories:", response.json())
        return {}

    data = response.json()
    category_mapping = {item["id"]: item["snippet"]["title"] for item in data["items"]}
    return category_mapping

# ğŸ“Œ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ê°€ì ¸ì˜¤ê¸°
CATEGORY_MAPPING = get_category_mapping()

# ğŸ“Œ ë°ì´í„° ì €ì¥ í´ë” (`backend/data/`)
BASE_DIR = os.path.dirname(os.path.dirname(__file__))  # ğŸ”¥ `backend/` ë””ë ‰í† ë¦¬ ê²½ë¡œ
DATA_DIR = os.path.join(BASE_DIR, "data")  # `backend/data/` í´ë”
os.makedirs(DATA_DIR, exist_ok=True)  # âœ… í´ë” ì—†ìœ¼ë©´ ìë™ ìƒì„±


# ğŸ“Œ ìœ íŠœë¸Œ ì¸ê¸° ë™ì˜ìƒ ê°€ì ¸ì˜¤ê¸° (ìµœëŒ€ 200ê°œ)
def get_trending_videos(region_code="KR", max_results=200):
    videos = []
    next_page_token = None
    total_fetched = 0  # âœ… ê°€ì ¸ì˜¨ ì´ ê°œìˆ˜

    while total_fetched < max_results:
        fetch_size = min(50, max_results - total_fetched)  # âœ… ë‚¨ì€ ê°œìˆ˜ë§Œí¼ ìš”ì²­
        url = f"{BASE_URL}videos?part=snippet,statistics&chart=mostPopular&regionCode={region_code}&maxResults={fetch_size}&key={API_KEY}"

        if next_page_token:
            url += f"&pageToken={next_page_token}"

        response = requests.get(url)
        if response.status_code != 200:
            print("âŒ API ìš”ì²­ ì‹¤íŒ¨:", response.json())
            break

        data = response.json()
        videos.extend(data["items"])  # âœ… ë°ì´í„° ì¶”ê°€
        total_fetched += len(data["items"])  # âœ… ì´ ê°œìˆ˜ ì—…ë°ì´íŠ¸

        next_page_token = data.get("nextPageToken")  # âœ… ë‹¤ìŒ í˜ì´ì§€ í† í° ì—…ë°ì´íŠ¸
        if not next_page_token:
            break  # âœ… ë” ì´ìƒ ê°€ì ¸ì˜¬ ë°ì´í„° ì—†ìŒ

    return pd.DataFrame([{
        "video_id": item["id"],
        "title": item["snippet"]["title"],
        "channel": item["snippet"]["channelTitle"],
        "category": CATEGORY_MAPPING.get(item["snippet"].get("categoryId", "Unknown"), "Unknown"),  # âœ… ID â†’ ì´ë¦„ ë³€í™˜
        "published_at": item["snippet"]["publishedAt"],
        "views": int(item["statistics"].get("viewCount", 0)),
        "likes": int(item["statistics"].get("likeCount", 0)),
        "comments": int(item["statistics"].get("commentCount", 0)),
        "fetched_at": datetime.utcnow()  # âœ… ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ ì‹œì  ê¸°ë¡
    } for item in videos])


# ğŸ“Œ ë°ì´í„° ì €ì¥ í•¨ìˆ˜ (ì¤‘ë³µ í™•ì¸ í›„ ì €ì¥)
def save_to_db(df):
    with app.app_context():
        for _, row in df.iterrows():
            # âœ… ì¤‘ë³µ ë°ì´í„° í™•ì¸ (video_idê°€ DBì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸)
            existing_video = YouTubeTrending.query.filter_by(video_id=row["video_id"]).first()
            if not existing_video:
                new_video = YouTubeTrending(
                    video_id=row["video_id"],
                    title=row["title"],
                    channel=row["channel"],
                    category=row["category"],
                    views=row["views"],
                    likes=row["likes"],
                    comments=row["comments"],
                    published_at=datetime.strptime(row["published_at"], "%Y-%m-%dT%H:%M:%SZ"),
                    fetched_at=row["fetched_at"]
                )
                db.session.add(new_video)

        db.session.commit()  # âœ… ëª¨ë“  ë°ì´í„° ì €ì¥ ì™„ë£Œ
        print("âœ… ë°ì´í„°ê°€ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")


# ğŸ“Œ ì¸ê¸° ë™ì˜ìƒ ê°€ì ¸ì˜¤ê¸° (ìµœëŒ€ 200ê°œ)
df = get_trending_videos(region_code="KR", max_results=200)

if df is not None:
    # âœ… CSV ì €ì¥ (ë°±ì—… ìš©ë„)
    csv_path = os.path.join(DATA_DIR, "youtube_trending_data.csv")
    df.to_csv(csv_path, index=False)
    print(f"âœ… ë°ì´í„°ê°€ {csv_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # âœ… DB ì €ì¥ ì‹¤í–‰
    save_to_db(df)
